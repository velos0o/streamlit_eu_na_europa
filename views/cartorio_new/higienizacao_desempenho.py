import streamlit as st
import pandas as pd
from data.load_conclusao_higienizacao import load_conclusao_data
from views.cartorio_new.data_loader import carregar_dados_cartorio # Importar dados do cart√≥rio
from datetime import datetime, timedelta, date
import re # Para extrair ID da op√ß√£o do selectbox
import numpy as np # Para opera√ß√µes num√©ricas

def aplicar_logica_precedencia_pipeline_104_higienizacao(df):
    """
    Aplica l√≥gica de preced√™ncia espec√≠fica para higieniza√ß√£o no pipeline 104.
    
    CORRIGIDA DEZEMBRO 2024: Melhorada para tratar adequadamente a l√≥gica de duplica√ß√£o
    
    Regras especiais para higieniza√ß√£o:
    1. Se pipeline 104 tem registros EM ANDAMENTO E existe pipeline superior (92, 94, 102):
       - Manter ambos (s√£o processos paralelos)
    2. Se pipeline 104 tem "PESQUISA PRONTA PARA EMISS√ÉO" E existe pipeline superior ATIVO:
       - Ajustar para evitar duplica√ß√£o nas m√©tricas de "Pasta C/Emiss√£o Conclu√≠da"
    3. Se pipeline 104 √© o √öNICO para a fam√≠lia: manter na contagem sempre
    
    IMPORTANTE: Ser mais conservador para n√£o remover dados importantes
    """
    if 'CATEGORY_ID' not in df.columns or 'UF_CRM_34_ID_FAMILIA' not in df.columns:
        return df
    
    df_processado = df.copy()
    
    # Identificar fam√≠lias que t√™m pipeline 104
    familias_104 = df_processado[
        df_processado['CATEGORY_ID'].astype(str) == '104'
    ]['UF_CRM_34_ID_FAMILIA'].unique()
    
    if len(familias_104) == 0:
        return df_processado
    
    # Para cada fam√≠lia com 104, verificar se h√° conflito real de duplica√ß√£o
    familias_para_ajustar_104 = []
    
    for id_familia in familias_104:
        registros_familia = df_processado[df_processado['UF_CRM_34_ID_FAMILIA'] == id_familia]
        
        # Verificar registros por pipeline
        registros_104 = registros_familia[registros_familia['CATEGORY_ID'].astype(str) == '104']
        registros_superiores = registros_familia[registros_familia['CATEGORY_ID'].astype(str).isin(['92', '94', '102'])]
        
        # Se tem pipelines superiores E pipeline 104
        if not registros_superiores.empty and not registros_104.empty:
            # Verificar se h√° 104 "pronto para emiss√£o" 
            tem_104_pronto = registros_104['STAGE_ID'].str.contains('SUCCESS', na=False).any()
            
            # Verificar se os pipelines superiores est√£o ativos
            superiores_com_sucesso = registros_superiores['STAGE_ID'].str.contains('SUCCESS', na=False).any()
            
            if tem_104_pronto and superiores_com_sucesso:
                # Se h√° clara duplica√ß√£o (ambos prontos/conclu√≠dos)
                familias_para_ajustar_104.append(id_familia)
                print(f"[DEBUG HIGIENIZA√á√ÉO] FAM√çLIA {id_familia}: Pipeline 104 pronto com pipeline superior conclu√≠do, ajustando para evitar duplica√ß√£o")
            else:
                print(f"[DEBUG HIGIENIZA√á√ÉO] FAM√çLIA {id_familia}: Pipeline 104 e superiores coexistindo normalmente")
        else:
            print(f"[DEBUG HIGIENIZA√á√ÉO] FAM√çLIA {id_familia}: Apenas pipeline 104 ou sem conflito, mantendo na contagem")
    
    # AJUSTE CONSERVADOR: Em vez de remover completamente, apenas ajustar a contagem
    # quando h√° duplica√ß√£o clara
    if familias_para_ajustar_104:
        # Para higieniza√ß√£o, vamos manter uma abordagem mais conservadora
        # Removendo apenas quando h√° duplica√ß√£o muito clara
        familias_para_remover_realmente = []
        
        for id_familia in familias_para_ajustar_104:
            registros_familia = df_processado[df_processado['UF_CRM_34_ID_FAMILIA'] == id_familia]
            registros_104 = registros_familia[registros_familia['CATEGORY_ID'].astype(str) == '104']
            registros_superiores = registros_familia[registros_familia['CATEGORY_ID'].astype(str).isin(['92', '94', '102'])]
            
            # Verificar se h√° duplica√ß√£o MUITO clara (ambos conclu√≠dos)
            tem_104_success = registros_104['STAGE_ID'].str.contains('SUCCESS', na=False).any()
            tem_superiores_success = registros_superiores['STAGE_ID'].str.contains('SUCCESS', na=False).any()
            
            if tem_104_success and tem_superiores_success:
                # S√≥ remover quando ambos est√£o "SUCCESS" (duplica√ß√£o clara)
                familias_para_remover_realmente.append(id_familia)
        
        if familias_para_remover_realmente:
            mask_remover = (
                df_processado['UF_CRM_34_ID_FAMILIA'].isin(familias_para_remover_realmente) &
                (df_processado['CATEGORY_ID'].astype(str) == '104')
            )
            df_processado = df_processado[~mask_remover].copy()
            print(f"[DEBUG HIGIENIZA√á√ÉO] Removidos {mask_remover.sum()} registros do pipeline 104 devido √† duplica√ß√£o clara")
    
    return df_processado

# Fun√ß√£o auxiliar para garantir tipos num√©ricos corretos para exibi√ß√£o
def ensure_numeric_display(df):
    # Lista de colunas que devem ser inteiras
    int_columns = [
        'PASTAS TOTAIS', 'HIGINIZA√á√ÉO COM √äXITO', 'HIGINIZA√á√ÉO INCOMPLETA',
        'HIGINIZA√á√ÉO TRATADAS', 'DISTRATO', 'Brasileiras Pend√™ncias',
        'Brasileiras Pesquisas', 'Brasileiras Solicitadas', 'Brasileiras Emitida',
        'Pasta C/Emiss√£o Conclu√≠da', 'Brasileiras Dispensada'
    ]
    
    # Lista de colunas que devem ser float (percentuais)
    percent_columns = ['CONVERS√ÉO (%)', 'Taxa Emiss√£o Conclu√≠da (%)']
    
    # Lista de colunas que devem ser strings
    string_columns = ['MESA', 'CONSULTOR']
    
    df_clean = df.copy()
    
    # Tratar colunas inteiras
    for col in int_columns:
        if col in df_clean.columns:
            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0).astype(int)
    
    # Tratar colunas de porcentagem - manter como float em vez de strings
    for col in percent_columns:
        if col in df_clean.columns:
            # Remover o s√≠mbolo "%" se existir e converter para n√∫mero
            if df_clean[col].dtype == object:
                df_clean[col] = pd.to_numeric(df_clean[col].astype(str).str.replace('%', '').str.strip(), errors='coerce').fillna(0)
            else:
                df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0)
            # Arredondar para 2 casas decimais, mas manter como float (sem converter para string)
            df_clean[col] = df_clean[col].round(2)
    
    # Tratar colunas de texto
    for col in string_columns:
        if col in df_clean.columns:
            df_clean[col] = df_clean[col].fillna('').astype(str)
    
    return df_clean

def exibir_higienizacao_desempenho():
    """
    Exibe a tabela de desempenho da higieniza√ß√£o por mesa e consultor,
    com op√ß√£o de filtro por data e dados de emiss√µes do Bitrix.
    """
    # Fun√ß√£o auxiliar para converter DataFrame para CSV
    @st.cache_data
    def convert_df_to_csv(df):
        return df.to_csv(index=False).encode('utf-8')

    st.subheader("Desempenho da Higieniza√ß√£o por Mesa")

    # --- Carregar CSS Compilado ---
    try:
        with open('assets/styles/css/main.css', 'r', encoding='utf-8') as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
    except FileNotFoundError:
        st.warning("Arquivo CSS principal (main.css) n√£o encontrado.")

    # --- FILTROS UNIFICADOS ---
    with st.expander("üìä Filtros", expanded=True):
        st.markdown('<div class="filtros-container">', unsafe_allow_html=True)
        
        # --- SE√á√ÉO 1: FILTROS DE DATA ---
        st.markdown('<div class="filtro-section">', unsafe_allow_html=True)
        st.markdown('<label class="filtro-label">Filtros de Data</label>', unsafe_allow_html=True)
        
        col_data1, col_data2, col_data_check = st.columns([2,2,1])
        
        with col_data1:
            data_inicio_filtro = st.date_input("Data In√≠cio (Opcional)", value=None, key="data_inicio_filtro")
        with col_data2:
            data_fim_filtro = st.date_input("Data Fim (Opcional)", value=None, key="data_fim_filtro")
        with col_data_check:
            st.markdown("<div style='margin-top: 28px;'></div>", unsafe_allow_html=True)
            aplicar_filtro_data = st.checkbox("Aplicar Datas", value=False, help="Marque para filtrar os dados da planilha pelo per√≠odo selecionado.", key="aplicar_filtro_data")
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # --- SE√á√ÉO 2: FILTROS ADICIONAIS ---
        st.markdown('<div class="filtro-section">', unsafe_allow_html=True)
        st.markdown('<label class="filtro-label">Filtros Adicionais</label>', unsafe_allow_html=True)
        
        col_ano, col_resp = st.columns(2)
        
        with col_ano:
            # Placeholder para ano - ser√° preenchido ap√≥s carregar dados
            ano_selecionado = st.empty()
            
        with col_resp:
            # Placeholder para respons√°veis - ser√° preenchido ap√≥s carregar dados
            filtro_responsaveis = st.empty()
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # --- SE√á√ÉO 3: FILTROS POR FAM√çLIA ---
        st.markdown('<div class="filtro-section">', unsafe_allow_html=True)
        st.markdown('<label class="filtro-label">Filtros por Fam√≠lia</label>', unsafe_allow_html=True)
        
        col_id, col_nome = st.columns(2)
        
        with col_id:
            filtro_id_familia = st.text_input("ID da Fam√≠lia (exato)", key="filtro_id_familia_higienizacao")
            filtro_id_familia = filtro_id_familia.strip()
            
        with col_nome:
            # Placeholder para fam√≠lias - ser√° preenchido ap√≥s carregar dados
            filtro_nome_familia_selecionado = st.empty()
        
        st.markdown('</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True) # Fecha filtros-container

    # Vari√°veis para passar para a fun√ß√£o de carregamento
    start_date_to_load = None
    end_date_to_load = None

    if aplicar_filtro_data:
        if data_inicio_filtro and data_fim_filtro:
            if data_inicio_filtro > data_fim_filtro:
                st.warning("A data de in√≠cio n√£o pode ser posterior √† data de fim.")
                return
            start_date_to_load = data_inicio_filtro
            end_date_to_load = data_fim_filtro
            st.info(f"Filtro de data aplicado: {start_date_to_load.strftime('%d/%m/%Y')} a {end_date_to_load.strftime('%d/%m/%Y')}")
            
            # Debug: Informar sobre o filtro de data
            print("\n=== DEBUG: Filtro de Data ===")
            print(f"Aplicando filtro de data: {start_date_to_load.strftime('%d/%m/%Y')} a {end_date_to_load.strftime('%d/%m/%Y')}")
        elif data_inicio_filtro or data_fim_filtro:
            st.warning("Por favor, selecione ambas as datas (in√≠cio e fim) para aplicar o filtro de data.")
            print("\n=== DEBUG: Tentativa de filtro de data incompleta ===")
            print(f"Data in√≠cio: {data_inicio_filtro}")
            print(f"Data fim: {data_fim_filtro}")
    else:
        print("\n=== DEBUG: Sem filtro de data aplicado ===")

    # --- Carregar Dados (Necess√°rio antes dos filtros por fam√≠lia para popular selectbox) ---
    # 1. Dados da Planilha de Conclus√£o
    spinner_message = "Carregando todos os dados de conclus√£o da planilha..."
    if start_date_to_load and end_date_to_load:
        spinner_message = f"Carregando dados de conclus√£o entre {start_date_to_load.strftime('%d/%m/%Y')} e {end_date_to_load.strftime('%d/%m/%Y')}..."
    
    with st.spinner(spinner_message):
        df_conclusao_raw = load_conclusao_data(start_date=start_date_to_load, end_date=end_date_to_load)
        if df_conclusao_raw is None:
             df_conclusao_raw = pd.DataFrame() # Continuar com DF vazio

        # Garantir colunas mesmo se vazio
        colunas_planilha_esperadas = [
            'responsavel', 'mesa', 'id_familia', 'nome_familia', 
            'higienizacao_exito', 'higienizacao_incompleta', 'higienizacao_tratadas',
            'higienizacao_distrato'  # Nova coluna adicionada
        ]
        for col in colunas_planilha_esperadas:
            if col not in df_conclusao_raw.columns:
                df_conclusao_raw[col] = None 

        colunas_planilha = [
            'responsavel', 'mesa', 'id_familia', 'nome_familia', 
            'higienizacao_exito', 'higienizacao_incompleta', 'higienizacao_tratadas',
            'higienizacao_distrato'  # Nova coluna adicionada
        ]
        df_conclusao_raw = df_conclusao_raw[colunas_planilha].copy()
        df_conclusao_raw = df_conclusao_raw.dropna(subset=['id_familia']) 

    # 2. Dados do Bitrix (Funil Emiss√µes 1098)
    with st.spinner("Carregando dados de emiss√µes do Bitrix..."):
        df_cartorio = carregar_dados_cartorio()
        if df_cartorio is None:
            df_cartorio = pd.DataFrame() 
            st.warning("N√£o foi poss√≠vel carregar os dados de emiss√µes do Bitrix.")
    
    # --- PREENCHER OS FILTROS AGORA QUE OS DADOS FORAM CARREGADOS ---

    # --- Filtro de Data de Venda ---
    # Obter anos dispon√≠veis a partir das datas de venda
    anos_disponiveis = []
    ano_atual = datetime.now().year
    
    if not df_cartorio.empty and 'DATA_VENDA_FAMILIA' in df_cartorio.columns:
        df_cartorio['DATA_VENDA_FAMILIA'] = pd.to_datetime(df_cartorio['DATA_VENDA_FAMILIA'], errors='coerce')
        df_com_data = df_cartorio.dropna(subset=['DATA_VENDA_FAMILIA'])
        
        if not df_com_data.empty:
            # Extrair apenas o ano das datas
            anos_disponiveis = sorted(df_com_data['DATA_VENDA_FAMILIA'].dt.year.unique().tolist())
    
    # Se n√£o houver anos na base, usar o ano atual como padr√£o
    if not anos_disponiveis:
        anos_disponiveis = [ano_atual]
    
    # Adicionar op√ß√£o para "Todos os anos"
    opcoes_anos = ["Todos os anos"] + [str(ano) for ano in anos_disponiveis]

    # Preencher o selectbox de ano
    with ano_selecionado.container():
        ano_selecionado_valor = st.selectbox(
            "Filtrar por Ano de Venda",
            options=opcoes_anos,
            index=0,
            key="ano_venda_select"
        )

    # --- Filtro de Respons√°vel ---
    # Obter lista de respons√°veis √∫nicos
    responsaveis_unicos = []
    responsaveis_mapeamento = {}  # Para mapear nomes normalizados -> originais
    
    # Dicion√°rio de corre√ß√µes para casos espec√≠ficos com varia√ß√£o ortogr√°fica
    correcoes_ortograficas = {
        "DANYELLE": "DANYELE",  # Varia√ß√µes da mesma pessoa
        "VITOR": "VICTOR",      # Casos onde podem ser a mesma pessoa
        "VICTOR": "VICTOR"
    }

    # Fun√ß√£o para normalizar nomes (extrair apenas primeiro nome)
    def normalizar_nome(nome):
        if not nome or not isinstance(nome, str):
            return ""
        # Pegar apenas o primeiro nome 
        primeiro_nome = nome.strip().split()[0].upper()
        
        # Aplicar corre√ß√µes ortogr√°ficas se existirem
        if primeiro_nome in correcoes_ortograficas:
            primeiro_nome = correcoes_ortograficas[primeiro_nome]
            
        return primeiro_nome
    
    # Da tabela de conclus√£o
    if not df_conclusao_raw.empty and 'responsavel' in df_conclusao_raw.columns:
        responsaveis_planilha = df_conclusao_raw['responsavel'].dropna().unique().tolist()
        for resp in responsaveis_planilha:
            if not resp or str(resp).strip() == '':
                continue
            nome_norm = normalizar_nome(resp)
            if nome_norm:
                # Mapear o nome normalizado para o original
                if nome_norm not in responsaveis_mapeamento:
                    responsaveis_mapeamento[nome_norm] = [resp]
                elif resp not in responsaveis_mapeamento[nome_norm]:
                    responsaveis_mapeamento[nome_norm].append(resp)
    
    # Do Bitrix
    if not df_cartorio.empty and 'ASSIGNED_BY_NAME' in df_cartorio.columns:
        responsaveis_bitrix = df_cartorio['ASSIGNED_BY_NAME'].dropna().unique().tolist()
        for resp in responsaveis_bitrix:
            if not resp or str(resp).strip() == '':
                continue
            nome_norm = normalizar_nome(resp)
            if nome_norm:
                # Mapear o nome normalizado para o original
                if nome_norm not in responsaveis_mapeamento:
                    responsaveis_mapeamento[nome_norm] = [resp]
                elif resp not in responsaveis_mapeamento[nome_norm]:
                    responsaveis_mapeamento[nome_norm].append(resp)
    
    # Criar lista de nomes normalizados (apenas primeiro nome) para o filtro
    responsaveis_unicos = sorted(list(responsaveis_mapeamento.keys()))

    # Debug: mostrar o mapeamento de nomes
    print("\n=== DEBUG: Mapeamento de nomes de respons√°veis ===")
    for nome_norm, variantes in responsaveis_mapeamento.items():
        print(f"{nome_norm}: {variantes}")
    print("=== FIM DEBUG ===\n")
    
    # Preparar a mensagem de ajuda com as corre√ß√µes aplicadas
    correcoes_info = ", ".join([f"{k} ‚Üí {v}" for k, v in correcoes_ortograficas.items() if k != v])
    mensagem_ajuda = f"Selecione o respons√°vel pelo primeiro nome. Varia√ß√µes de sobrenome e algumas corre√ß√µes ortogr√°ficas ({correcoes_info}) foram unificadas."

    # Preencher o multiselect de respons√°veis
    with filtro_responsaveis.container():
        filtro_responsaveis_valor = st.multiselect(
            "Filtrar por Respons√°vel",
            options=responsaveis_unicos,
            default=[],
            placeholder="Selecione um ou mais respons√°veis",
            key="filtro_responsaveis_higienizacao",
            help=mensagem_ajuda
        )

    # --- Filtro por Fam√≠lia ---
    opcoes_familia = ["Todas"] 
    if not df_conclusao_raw.empty:
        df_conclusao_raw['nome_familia'] = df_conclusao_raw['nome_familia'].fillna('Sem Nome')
        df_conclusao_raw['responsavel'] = df_conclusao_raw['responsavel'].fillna('Sem Respons√°vel')
        df_conclusao_raw['id_familia'] = df_conclusao_raw['id_familia'].astype(str) 

        df_conclusao_raw['opcao_selectbox'] = df_conclusao_raw.apply(
            lambda row: f"{row['nome_familia']} \\\\ {row['responsavel']} \\\\ {row['id_familia']}", axis=1
        )
        lista_opcoes = sorted(df_conclusao_raw['opcao_selectbox'].unique().tolist())
        opcoes_familia.extend(lista_opcoes)

    # Preencher o selectbox de fam√≠lias
    with filtro_nome_familia_selecionado.container():
        filtro_nome_familia_selecionado_valor = st.selectbox(
            "Nome da Fam√≠lia (\\ Respons√°vel \\ ID)", 
            options=opcoes_familia, 
            key="filtro_nome_familia_higienizacao"
        )

    # --- Aplicar Filtros por Fam√≠lia (afeta df_conclusao_raw e df_cartorio) --- 
    id_familia_filtrar = None

    if filtro_id_familia:
        id_familia_filtrar = filtro_id_familia
        st.info(f"Filtrando pelo ID da Fam√≠lia: {id_familia_filtrar}")
    elif filtro_nome_familia_selecionado_valor != "Todas":
        match = re.search(r'\\\\ ([^\\\\]+)$', filtro_nome_familia_selecionado_valor)
        if match:
            id_familia_filtrar = match.group(1).strip()
            st.info(f"Filtrando pela fam√≠lia selecionada (ID: {id_familia_filtrar})")
        else:
            st.warning("N√£o foi poss√≠vel extrair o ID da fam√≠lia da op√ß√£o selecionada.")

    if id_familia_filtrar:
        df_conclusao_raw = df_conclusao_raw[df_conclusao_raw['id_familia'] == id_familia_filtrar].copy()
        if not df_cartorio.empty and 'UF_CRM_34_ID_FAMILIA' in df_cartorio.columns:
            df_cartorio = df_cartorio[df_cartorio['UF_CRM_34_ID_FAMILIA'] == id_familia_filtrar].copy()
        
        if df_conclusao_raw.empty:
             st.warning(f"Nenhum dado de higieniza√ß√£o encontrado para a fam√≠lia ID: {id_familia_filtrar} no per√≠odo selecionado.")
             if 'df_bitrix_agg' in locals(): df_bitrix_agg = pd.DataFrame(columns=df_bitrix_agg.columns if hasattr(df_bitrix_agg, 'columns') else [])

    # --- Aplicar Filtro de Data de Venda ---
    if not df_cartorio.empty and 'DATA_VENDA_FAMILIA' in df_cartorio.columns:
        if ano_selecionado_valor != "Todos os anos":
            # Converter para inteiro para comparar com o ano extra√≠do das datas
            ano_filtro = int(ano_selecionado_valor)
            
            # Filtrar df_cartorio apenas pelo ano selecionado
            df_cartorio = df_cartorio[df_cartorio['DATA_VENDA_FAMILIA'].dt.year == ano_filtro].copy()
            
            if df_cartorio.empty:
                st.warning(f"Nenhum dado encontrado para o ano selecionado: {ano_selecionado_valor}")
            else:
                st.success(f"Filtro aplicado: Mostrando dados do ano {ano_selecionado_valor} ({len(df_cartorio)} registros)")
        else:
            # Se "Todos os anos" for selecionado, n√£o aplicar filtro de ano
            st.info("Mostrando dados de todos os anos dispon√≠veis")
            
    # --- Aplicar Filtro de Respons√°vel ---
    if filtro_responsaveis_valor:
        # Expandir os nomes normalizados para incluir todas as varia√ß√µes
        nomes_expandidos = []
        for nome_norm in filtro_responsaveis_valor:
            if nome_norm in responsaveis_mapeamento:
                nomes_expandidos.extend(responsaveis_mapeamento[nome_norm])
        
        # Debug: mostrar os nomes expandidos
        print("\n=== DEBUG: Nomes expandidos para filtro ===")
        print(f"Nomes normalizados selecionados: {filtro_responsaveis_valor}")
        print(f"Nomes expandidos para filtro: {nomes_expandidos}")
        print("=== FIM DEBUG ===\n")
        
        # Filtrar df_conclusao_raw por respons√°vel (usando todas as varia√ß√µes)
        if not df_conclusao_raw.empty and 'responsavel' in df_conclusao_raw.columns:
            df_conclusao_raw = df_conclusao_raw[df_conclusao_raw['responsavel'].isin(nomes_expandidos)].copy()
        
        # Filtrar df_cartorio por respons√°vel (usando todas as varia√ß√µes)
        if not df_cartorio.empty and 'ASSIGNED_BY_NAME' in df_cartorio.columns:
            df_cartorio = df_cartorio[df_cartorio['ASSIGNED_BY_NAME'].isin(nomes_expandidos)].copy()
        
        if df_conclusao_raw.empty and df_cartorio.empty:
            nomes_str = ', '.join(filtro_responsaveis_valor)
            st.warning(f"Nenhum dado encontrado para o(s) respons√°vel(eis) selecionado(s): {nomes_str}")

    # --- MOVER PROCESSAMENTO DE DADOS PARA ANTES DAS FAIXAS ---

    # --- APLICAR L√ìGICA ESPECIAL PARA PIPELINE 104 (PESQUISA BR) ---
    # Aplicar l√≥gica de preced√™ncia antes de calcular m√©tricas
    if not df_cartorio.empty and 'CATEGORY_ID' in df_cartorio.columns:
        df_cartorio = aplicar_logica_precedencia_pipeline_104_higienizacao(df_cartorio)

    # --- Mapeamento de Est√°gios Bitrix ---
    # ATUALIZADO: Incluindo os novos funis 102 (Par√≥quia) e 104 (Pesquisa BR)
    mapeamento_stages = {
        # === Pipeline 92 ===
        'DT1098_92:NEW': 'Brasileiras Pend√™ncias', 
        'DT1098_92:UC_P6PYHW': 'Brasileiras Pesquisas',
        'DT1098_92:PREPARATION': 'Brasileiras Pend√™ncias', 
        'DT1098_92:UC_XBTHZ7': 'Brasileiras Pend√™ncias',
        'DT1098_92:CLIENT': 'Brasileiras Pend√™ncias', 
        'DT1098_92:UC_ZWO7BI': 'Brasileiras Pend√™ncias',
        'DT1098_92:UC_83ZGKS': 'Brasileiras Pend√™ncias', 
        'DT1098_92:UC_6TECYL': 'Brasileiras Pend√™ncias',
        'DT1098_92:UC_MUJP1P': 'Brasileiras Solicitadas', 
        'DT1098_92:UC_EYBGVD': 'Brasileiras Pend√™ncias',
        'DT1098_92:UC_KC335Q': 'Brasileiras Pend√™ncias', 
        'DT1098_92:UC_5LWUTX': 'Brasileiras Emitida',
        'DT1098_92:FAIL': 'Brasileiras Dispensada', 
        'DT1098_92:UC_Z24IF7': 'Brasileiras Dispensada',
        'DT1098_92:UC_U10R0R': 'Brasileiras Dispensada', 
        'DT1098_92:SUCCESS': 'Brasileiras Emitida',
        
        # === Pipeline 94 ===
        'DT1098_94:NEW': 'Brasileiras Pend√™ncias', 
        'DT1098_94:UC_4YE2PI': 'Brasileiras Pesquisas',
        'DT1098_94:PREPARATION': 'Brasileiras Pend√™ncias', 
        'DT1098_94:CLIENT': 'Brasileiras Pend√™ncias',
        'DT1098_94:UC_IQ4WFA': 'Brasileiras Pend√™ncias', 
        'DT1098_94:UC_UZHXWF': 'Brasileiras Pend√™ncias',
        'DT1098_94:UC_DH38EI': 'Brasileiras Pend√™ncias', 
        'DT1098_94:UC_X9UE60': 'Brasileiras Pend√™ncias',
        'DT1098_94:UC_IXCAA5': 'Brasileiras Solicitadas', 
        'DT1098_94:UC_VS8YKI': 'Brasileiras Pend√™ncias',
        'DT1098_94:UC_M6A09E': 'Brasileiras Pend√™ncias', 
        'DT1098_94:UC_K4JS04': 'Brasileiras Emitida',
        'DT1098_94:FAIL': 'Brasileiras Dispensada', 
        'DT1098_94:UC_MGTPX0': 'Brasileiras Dispensada',
        'DT1098_94:UC_L3JFKO': 'Brasileiras Dispensada', 
        'DT1098_94:SUCCESS': 'Brasileiras Emitida',
        
        # === Pipeline 102 (Par√≥quia) ===
        'DT1098_102:NEW': 'Brasileiras Pend√™ncias',
        'DT1098_102:PREPARATION': 'Brasileiras Pend√™ncias',
        'DT1098_102:CLIENT': 'Brasileiras Emitida',
        'DT1098_102:UC_45SBLC': 'Brasileiras Pend√™ncias',  # Devolu√ß√£o ADM como pend√™ncia
        'DT1098_102:SUCCESS': 'Brasileiras Emitida',  # Certid√£o Entregue
        'DT1098_102:FAIL': 'Brasileiras Dispensada',  # Cancelado
        'DT1098_102:UC_676WIG': 'Brasileiras Dispensada',  # Certid√£o Dispensada
        'DT1098_102:UC_UHPXE8': 'Brasileiras Emitida',  # Certid√£o Entregue
        
        # === Pipeline 104 (Pesquisa BR) - L√ìGICA ESPECIAL ===
        # IMPORTANTE: Pipeline 104 ser√° tratado de forma especial na fun√ß√£o aplicar_logica_precedencia_pipeline_104
        'DT1098_104:NEW': 'Brasileiras Pesquisas',  # Aguardando Pesquisador
        'DT1098_104:PREPARATION': 'Brasileiras Pesquisas',  # Pesquisa em Andamento
        'DT1098_104:SUCCESS': 'Brasileiras Pesquisas',  # Pesquisa Pronta - consideramos como pesquisa finalizada
        'DT1098_104:FAIL': 'Brasileiras Dispensada',  # Pesquisa N√£o Encontrada
    }
    col_id_familia_bitrix = 'UF_CRM_34_ID_FAMILIA'
    df_bitrix_agg = pd.DataFrame() # Inicializar df_bitrix_agg

    if not df_cartorio.empty and 'STAGE_ID' in df_cartorio.columns and col_id_familia_bitrix in df_cartorio.columns:
        df_cartorio['CATEGORIA_EMISSAO'] = df_cartorio['STAGE_ID'].map(mapeamento_stages).fillna('Categoria Desconhecida')
        
        # NOVO: Adicionar coluna de conclus√£o corrigida para cada registro
        df_cartorio['CONCLUIDA_CORRIGIDA'] = df_cartorio.apply(
            lambda row: calcular_conclusao_corrigida_por_pipeline(row), axis=1
        )
        
        df_bitrix_agg = pd.crosstab(df_cartorio[col_id_familia_bitrix], df_cartorio['CATEGORIA_EMISSAO'])
        
        categorias_bitrix_contagem = [
            'Brasileiras Pend√™ncias', 'Brasileiras Pesquisas', 'Brasileiras Solicitadas',
            'Brasileiras Emitida', 'Brasileiras Dispensada'
        ]
        for col in categorias_bitrix_contagem:
            if col not in df_bitrix_agg.columns:
                 df_bitrix_agg[col] = 0
        
        if 'Categoria Desconhecida' in df_bitrix_agg.columns:
            if 'Brasileiras Pend√™ncias' in df_bitrix_agg.columns:
                df_bitrix_agg['Brasileiras Pend√™ncias'] += df_bitrix_agg['Categoria Desconhecida']
            else:
                df_bitrix_agg['Brasileiras Pend√™ncias'] = df_bitrix_agg['Categoria Desconhecida']
            df_bitrix_agg = df_bitrix_agg.drop(columns=['Categoria Desconhecida'], errors='ignore')

        df_bitrix_agg = df_bitrix_agg.reindex(columns=categorias_bitrix_contagem, fill_value=0)
        
        # CORRIGIDO: Calcular "Pasta C/Emiss√£o Conclu√≠da" usando a l√≥gica corrigida
        # Primeiro, agrupar por fam√≠lia e verificar se TODAS as certid√µes est√£o realmente conclu√≠das
        conclusao_por_familia = df_cartorio.groupby(col_id_familia_bitrix).agg({
            'CONCLUIDA_CORRIGIDA': ['count', 'sum']
        })
        conclusao_por_familia.columns = ['total_certidoes', 'total_concluidas']
        conclusao_por_familia = conclusao_por_familia.reset_index()
        
        # Uma fam√≠lia est√° "C/Emiss√£o Conclu√≠da" apenas se TODAS as certid√µes est√£o conclu√≠das
        # E se h√° pelo menos uma certid√£o (evitar divis√£o por zero)
        conclusao_por_familia['familia_concluida'] = (
            (conclusao_por_familia['total_certidoes'] > 0) &
            (conclusao_por_familia['total_concluidas'] == conclusao_por_familia['total_certidoes'])
        ).astype(int)
        
        # Merge com df_bitrix_agg para adicionar a coluna corrigida
        df_bitrix_agg = pd.merge(
            df_bitrix_agg.reset_index(),
            conclusao_por_familia[[col_id_familia_bitrix, 'familia_concluida']],
            on=col_id_familia_bitrix,
            how='left'
        )
        
        # Renomear e garantir que existe
        df_bitrix_agg['Pasta C/Emiss√£o Conclu√≠da'] = df_bitrix_agg['familia_concluida'].fillna(0).astype(int)
        df_bitrix_agg = df_bitrix_agg.drop(columns=['familia_concluida'], errors='ignore')
        
        print(f"[DEBUG HIGIENIZA√á√ÉO] C√°lculo corrigido: {df_bitrix_agg['Pasta C/Emiss√£o Conclu√≠da'].sum()} fam√≠lias com emiss√£o conclu√≠da")
        
    else:
        df_bitrix_agg = pd.DataFrame()

    # Garantir que todas as colunas necess√°rias existam
    novas_colunas_bitrix = [
        'Brasileiras Pend√™ncias', 'Brasileiras Pesquisas', 'Brasileiras Solicitadas',
        'Brasileiras Emitida', 'Pasta C/Emiss√£o Conclu√≠da', 'Brasileiras Dispensada'
    ]
    
    if df_bitrix_agg.empty: # Se df_bitrix_agg n√£o foi populado (ex: df_cartorio vazio)
        colunas_esperadas_bitrix_vazio = [col_id_familia_bitrix] + novas_colunas_bitrix
        df_bitrix_agg = pd.DataFrame(columns=colunas_esperadas_bitrix_vazio)

    # --- Merge: Planilha + Dados Bitrix Agregados --- 
    df_merged = pd.merge(
        df_conclusao_raw, df_bitrix_agg,
        left_on='id_familia', right_on=col_id_familia_bitrix, how='left'
    )
    for col in novas_colunas_bitrix: # Preencher NaNs nas colunas do Bitrix com 0
        if col not in df_merged.columns: # Adicionar coluna se n√£o existir do merge
            df_merged[col] = 0
        df_merged[col] = df_merged[col].fillna(0).astype(int)

    # --- Agrega√ß√£o Final por Mesa e Consultor --- 
    agg_dict = {
        'higienizacao_exito': 'sum',
        'higienizacao_incompleta': 'sum',
        'higienizacao_tratadas': 'sum',
        'higienizacao_distrato': 'sum',  # Nova coluna adicionada
        'Brasileiras Pend√™ncias': 'sum',
        'Brasileiras Pesquisas': 'sum',
        'Brasileiras Solicitadas': 'sum',
        'Brasileiras Emitida': 'sum',
        'Pasta C/Emiss√£o Conclu√≠da': 'sum',
        'Brasileiras Dispensada': 'sum'
    }

    # Debug: Imprimir dados antes da agrega√ß√£o
    print("\n=== DEBUG: Dados antes da agrega√ß√£o ===")
    print(f"Total de registros em df_merged: {len(df_merged)}")
    print("\nContagens por status:")
    if 'higienizacao_exito' in df_merged.columns:
        print(f"Higieniza√ß√£o com √äxito (soma total): {df_merged['higienizacao_exito'].sum()}")
        # Mostrar contagem por mesa
        print("\nContagem de √äxito por Mesa:")
        print(df_merged.groupby('mesa')['higienizacao_exito'].sum())
    else:
        print("Coluna 'higienizacao_exito' n√£o encontrada!")
    print("=== FIM DEBUG ===\n")

    df_agregado_final = df_merged.groupby(['mesa', 'responsavel']).agg(agg_dict).reset_index()

    # Debug: Imprimir dados ap√≥s agrega√ß√£o
    print("\n=== DEBUG: Dados ap√≥s agrega√ß√£o ===")
    print(f"Total de registros em df_agregado_final: {len(df_agregado_final)}")
    print("\nSoma total de higieniza√ß√£o com √™xito ap√≥s agrega√ß√£o:")
    if 'higienizacao_exito' in df_agregado_final.columns:
        print(df_agregado_final['higienizacao_exito'].sum())
    print("=== FIM DEBUG ===\n")

    # --- Merge Final com a Base --- 
    data_base = {
        'MESA': ['MESA 8', 'MESA 7', 'MESA 6', 'MESA 5', 'MESA 4', 'MESA 3', 'MESA 2', 'MESA 1', 'MESA 0', 'Cabines', 'CARR√ÉO'],
        'PASTAS TOTAIS': [105, 46, 46, 70, 106, 46, 66, 66, 49, 113, 123],
        'CONSULTOR': ['NADYA', 'FELIPE', 'VITOR', 'BIANCA', 'DANYELE', 'LAYLA', 'LAYLA', 'JULIANE', 'JULIANE', 'STEFANY', 'Fernanda']
    }
    df_base = pd.DataFrame(data_base)

    # Garantir que a coluna MESA em df_base esteja em mai√∫sculas para o merge
    df_base['MESA'] = df_base['MESA'].str.upper()

    # Debug: Mostrar dados antes do merge
    print("\n=== DEBUG: Dados antes do merge final ===")
    print("df_base:")
    print(df_base)
    print("\ndf_agregado_final antes do rename:")
    print(df_agregado_final)

    # Primeiro, agregar os dados por MESA (somando todas as m√©tricas)
    metricas_para_somar = [
        'higienizacao_exito', 'higienizacao_incompleta', 'higienizacao_tratadas',
        'higienizacao_distrato', 'Brasileiras Pend√™ncias', 'Brasileiras Pesquisas',
        'Brasileiras Solicitadas', 'Brasileiras Emitida', 'Pasta C/Emiss√£o Conclu√≠da',
        'Brasileiras Dispensada'
    ]
    
    df_agregado_por_mesa = df_agregado_final.groupby('mesa')[metricas_para_somar].sum().reset_index()

    # Debug: Mostrar agrega√ß√£o por mesa
    print("\nAgrega√ß√£o por mesa (antes do rename):")
    print(df_agregado_por_mesa)

    # Renomear colunas
    df_agregado_por_mesa = df_agregado_por_mesa.rename(columns={
        'mesa': 'MESA',
        'higienizacao_exito': 'HIGINIZA√á√ÉO COM √äXITO',
        'higienizacao_incompleta': 'HIGINIZA√á√ÉO INCOMPLETA',
        'higienizacao_tratadas': 'HIGINIZA√á√ÉO TRATADAS',
        'higienizacao_distrato': 'DISTRATO'
    })

    # Debug: Mostrar ap√≥s rename
    print("\nAgrega√ß√£o por mesa (ap√≥s rename):")
    print(df_agregado_por_mesa)

    # Fazer o merge com a base
    df_final = pd.merge(df_base, df_agregado_por_mesa, on='MESA', how='left')

    # Preencher NaN com 0
    colunas_numericas = df_final.select_dtypes(include=['float64', 'int64']).columns
    df_final[colunas_numericas] = df_final[colunas_numericas].fillna(0)
    
    # Garantir que sejam n√∫meros inteiros onde apropriado
    colunas_inteiras = [
        'HIGINIZA√á√ÉO COM √äXITO', 'HIGINIZA√á√ÉO INCOMPLETA', 'HIGINIZA√á√ÉO TRATADAS', 
        'DISTRATO', 'Brasileiras Pend√™ncias', 'Brasileiras Pesquisas', 
        'Brasileiras Solicitadas', 'Brasileiras Emitida', 'Pasta C/Emiss√£o Conclu√≠da',
        'Brasileiras Dispensada'
    ]
    
    for col in colunas_inteiras:
        if col in df_final.columns:
            df_final[col] = df_final[col].fillna(0).astype(int)

    # --- Calcular m√©tricas ---
    df_final['CONVERS√ÉO (%)'] = np.where(
        df_final['PASTAS TOTAIS'] > 0,
        (df_final['HIGINIZA√á√ÉO COM √äXITO'] / df_final['PASTAS TOTAIS']) * 100,
        0
    )
    df_final['CONVERS√ÉO (%)'] = df_final['CONVERS√ÉO (%)'].fillna(0).round(2)

    df_final['Taxa Emiss√£o Conclu√≠da (%)'] = np.where(
        df_final['PASTAS TOTAIS'] > 0,
        (df_final['Pasta C/Emiss√£o Conclu√≠da'] / df_final['PASTAS TOTAIS']) * 100,
        0
    )
    df_final['Taxa Emiss√£o Conclu√≠da (%)'] = df_final['Taxa Emiss√£o Conclu√≠da (%)'].fillna(0).round(2)

    # Definir ordem das colunas
    ordem_colunas = [
        'MESA', 'PASTAS TOTAIS', 'CONSULTOR',
        'HIGINIZA√á√ÉO COM √äXITO', 'HIGINIZA√á√ÉO INCOMPLETA', 'HIGINIZA√á√ÉO TRATADAS',
        'DISTRATO', 'CONVERS√ÉO (%)',
        'Brasileiras Pend√™ncias', 'Brasileiras Pesquisas', 'Brasileiras Solicitadas',
        'Brasileiras Emitida', 'Pasta C/Emiss√£o Conclu√≠da', 'Taxa Emiss√£o Conclu√≠da (%)',
        'Brasileiras Dispensada'
    ]

    # Garantir que todas as colunas existam
    for col in ordem_colunas:
        if col not in df_final.columns:
            if col in ['CONVERS√ÉO (%)', 'Taxa Emiss√£o Conclu√≠da (%)']:
                df_final[col] = 0.0
            else:
                df_final[col] = 0

    df_final = df_final[ordem_colunas]

    # Debug: Mostrar dados ap√≥s c√°lculos
    print("\n=== DEBUG: Dados ap√≥s c√°lculos ===")
    print("df_final com todas as colunas:")
    print(df_final)

    # Renomear 'CABINES' para 'PROTOCOLADO' para exibi√ß√£o (ap√≥s o merge ter usado 'CABINES')
    df_final['MESA'] = df_final['MESA'].replace('CABINES', 'PROTOCOLADO')

    # --- Exibir a Tabela Principal (APENAS MESAS 1-8, para alinhar com o card acima) --- 
    mesas_1_8_list = [f'MESA {i}' for i in range(1, 9)] # Definindo a lista de mesas 1-8

    # Card para MESAS 1-8
    # Garantir que a coluna existe antes de somar
    if 'Pasta C/Emiss√£o Conclu√≠da' not in df_final.columns:
        df_final['Pasta C/Emiss√£o Conclu√≠da'] = 0
    df_final['Pasta C/Emiss√£o Conclu√≠da'] = pd.to_numeric(df_final['Pasta C/Emiss√£o Conclu√≠da'], errors='coerce').fillna(0).astype(int)
    
    total_mesas_1_8_card = df_final[df_final['MESA'].isin(mesas_1_8_list)]['Pasta C/Emiss√£o Conclu√≠da'].sum()

    st.markdown(f"""
    <div style="
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        border: 1px solid #dee2e6;
        border-radius: 8px;
        padding: 20px;
        margin: 15px 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    ">
        <div style="
            color: #495057;
            font-size: 14px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            margin-bottom: 8px;
            text-align: center;
        ">TOTAL DE PASTAS COM EMISS√ÉO CONCLU√çDA (MESAS 1-8)</div>
        <div style="
            color: #212529;
            font-size: 28px;
            font-weight: 700;
            text-align: center;
            margin: 0;
        ">{int(total_mesas_1_8_card)} PASTAS</div>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("---")
    
    # Filtrar dados para a tabela de MESAS 1-8 (excluindo PROTOCOLADO e CARR√ÉO explicitamente)
    df_display_mesas = df_final[
        df_final['MESA'].isin(mesas_1_8_list)
    ].copy()

    # Nos casos em que n√£o h√° dados reais para MESAS 1-8, mostrar mensagem amig√°vel
    # Usar df_display_mesas para a verifica√ß√£o
    if df_display_mesas.empty or ('HIGINIZA√á√ÉO COM √äXITO' in df_display_mesas.columns and df_display_mesas['HIGINIZA√á√ÉO COM √äXITO'].sum() == 0):
        st.warning("""
        N√£o foi poss√≠vel carregar os dados da planilha para as MESAS 1-8. Isso pode ocorrer por algumas raz√µes:
        
        1. A planilha pode estar com formato diferente do esperado
        2. Os cabe√ßalhos da planilha podem ter sido alterados
        3. Pode haver um problema de conex√£o com o Google Sheets
        
        Por favor, verifique a planilha e tente novamente.
        """)
        
        # Mostrar tabela b√°sica com as metas para MESAS 1-8 se os dados da planilha falharem
        df_base_mesas_1_8 = df_base[df_base['MESA'].isin(mesas_1_8_list)].copy()
        # Renomear 'Cabines' para 'PROTOCOLADO' tamb√©m em df_base se for exibido
        df_base_mesas_1_8['MESA'] = df_base_mesas_1_8['MESA'].replace('Cabines', 'PROTOCOLADO') 
        st.markdown("### Dados B√°sicos (Metas por Mesa 1-8)")
        st.dataframe(df_base_mesas_1_8, hide_index=True, use_container_width=True)
        # N√£o retornar a fun√ß√£o inteira, apenas a se√ß√£o de MESAS 1-8
    else:
        # --- Continua√ß√£o normal do c√≥digo se houver dados para MESAS 1-8 ---
        # Calcular totais para MESAS 1-8
        df_total_mesas = df_display_mesas.select_dtypes(include=np.number).sum().to_frame().T
        df_total_mesas['MESA'] = 'TOTAL'
        df_total_mesas['CONSULTOR'] = '' 
        
        # Recalcular percentuais para a linha de total
        if 'PASTAS TOTAIS' in df_total_mesas.columns and df_total_mesas['PASTAS TOTAIS'].iloc[0] > 0:
            if 'HIGINIZA√á√ÉO COM √äXITO' not in df_total_mesas.columns:
                df_total_mesas['HIGINIZA√á√ÉO COM √äXITO'] = 0
            df_total_mesas['CONVERS√ÉO (%)'] = (
                df_total_mesas['HIGINIZA√á√ÉO COM √äXITO'] / df_total_mesas['PASTAS TOTAIS'] * 100
            ).round(2)
            
            if 'Pasta C/Emiss√£o Conclu√≠da' not in df_total_mesas.columns:
                df_total_mesas['Pasta C/Emiss√£o Conclu√≠da'] = 0
            df_total_mesas['Taxa Emiss√£o Conclu√≠da (%)'] = (
                df_total_mesas['Pasta C/Emiss√£o Conclu√≠da'] / df_total_mesas['PASTAS TOTAIS'] * 100
            ).round(2)
        else:
            df_total_mesas['CONVERS√ÉO (%)'] = 0.0
            df_total_mesas['Taxa Emiss√£o Conclu√≠da (%)'] = 0.0
            
        df_total_mesas = ensure_numeric_display(df_total_mesas) # Aplicar formata√ß√£o
        df_display_mesas_final = pd.concat([df_display_mesas, df_total_mesas], ignore_index=True)
        df_display_mesas_final = ensure_numeric_display(df_display_mesas_final)

        st.markdown("""
        <style>
        table.dataframe {
            border-collapse: collapse;
            width: 100%;
            font-size: 14px;
        }
        table.dataframe th {
            background-color: #4a7bef;
            color: white;
            font-weight: bold;
            text-align: center;
            padding: 8px;
            border: 1px solid #dddddd;
        }
        table.dataframe td {
            text-align: center;
            padding: 6px;
            border: 1px solid #dddddd;
        }
        table.dataframe tr:nth-child(even) {
            background-color: #f2f2f2;
        }
        table.dataframe tr:hover {
            background-color: #ddd;
        }
        table.dataframe tr:last-child {
            background-color: #ffd580;
            font-weight: bold;
        }
        </style>
        """, unsafe_allow_html=True)
        
        df_percent = df_display_mesas_final.copy()
        if 'CONVERS√ÉO (%)' in df_percent.columns:
            df_percent['CONVERS√ÉO (%)'] = df_percent['CONVERS√ÉO (%)'].apply(lambda x: f"{x:.2f}%")
        if 'Taxa Emiss√£o Conclu√≠da (%)' in df_percent.columns:
            df_percent['Taxa Emiss√£o Conclu√≠da (%)'] = df_percent['Taxa Emiss√£o Conclu√≠da (%)'].apply(lambda x: f"{x:.2f}%")
        
        html_table = df_percent.to_html(index=False, classes='dataframe')
        st.markdown(html_table, unsafe_allow_html=True)

        csv_principal = convert_df_to_csv(df_display_mesas_final)
        st.download_button(
            label="Download Tabela MESAS 1-8 como CSV",
            data=csv_principal,
            file_name='desempenho_higienizacao_mesas_1_8.csv',
            mime='text/csv',
            key='download_mesas_1_8_csv'
        )
        st.markdown("---")

    # --- Exibir a Tabela de PROTOCOLADO --- 
    df_cabines_final = df_final[df_final['MESA'] == 'PROTOCOLADO'].copy()
    if not df_cabines_final.empty:
        # Verificar se a coluna Pasta C/Emiss√£o Conclu√≠da existe
        if 'Pasta C/Emiss√£o Conclu√≠da' not in df_cabines_final.columns:
            print("ALERTA: Criando coluna 'Pasta C/Emiss√£o Conclu√≠da' em df_cabines_final")
            df_cabines_final['Pasta C/Emiss√£o Conclu√≠da'] = 0
            
        # Garantir que √© um n√∫mero inteiro para exibi√ß√£o
        df_cabines_final['Pasta C/Emiss√£o Conclu√≠da'] = pd.to_numeric(df_cabines_final['Pasta C/Emiss√£o Conclu√≠da'], errors='coerce').fillna(0).astype(int)
        # Calcular total de Pasta C/Emiss√£o Conclu√≠da para PROTOCOLADO
        total_cabines = df_cabines_final['Pasta C/Emiss√£o Conclu√≠da'].sum()

        # Exibir card de PROTOCOLADO com design mais profissional e harm√¥nico
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        ">
            <div style="
                color: #495057;
                font-size: 14px;
                font-weight: 600;
                text-transform: uppercase;
                letter-spacing: 0.5px;
                margin-bottom: 8px;
                text-align: center;
            ">TOTAL DE PASTAS COM EMISS√ÉO CONCLU√çDA (PROTOCOLADO)</div>
            <div style="
                color: #212529;
                font-size: 28px;
                font-weight: 700;
                text-align: center;
                margin: 0;
            ">{int(total_cabines)} PASTAS</div>
        </div>
        """, unsafe_allow_html=True)
        st.markdown("---")

        if 'PASTAS TOTAIS' in df_cabines_final.columns:
            df_cabines_final.loc[:, 'PASTAS TOTAIS'] = pd.to_numeric(df_cabines_final['PASTAS TOTAIS'], errors='coerce').fillna(0).astype(int)

        df_total_cabines = df_cabines_final.select_dtypes(include=np.number).sum().to_frame().T
        df_total_cabines['MESA'] = 'TOTAL'
        df_display_cabines = pd.concat([df_cabines_final, df_total_cabines], ignore_index=True)

        # Aplicar formata√ß√£o num√©rica para garantir compatibilidade com Arrow
        df_display_cabines = ensure_numeric_display(df_display_cabines)
        
        # Formatar as colunas de porcentagem antes de converter para HTML
        df_percent_cabines = df_display_cabines.copy()
        if 'CONVERS√ÉO (%)' in df_percent_cabines.columns:
            df_percent_cabines['CONVERS√ÉO (%)'] = df_percent_cabines['CONVERS√ÉO (%)'].apply(lambda x: f"{x:.2f}%")
        if 'Taxa Emiss√£o Conclu√≠da (%)' in df_percent_cabines.columns:
            df_percent_cabines['Taxa Emiss√£o Conclu√≠da (%)'] = df_percent_cabines['Taxa Emiss√£o Conclu√≠da (%)'].apply(lambda x: f"{x:.2f}%")
        
        # Converter para HTML e exibir
        html_table_cabines = df_percent_cabines.to_html(index=False, classes='dataframe')
        st.markdown(html_table_cabines, unsafe_allow_html=True)
        
        csv_cabines_detalhes = convert_df_to_csv(df_cabines_final)
        st.download_button(
            label="Download Detalhes PROTOCOLADO como CSV",
            data=csv_cabines_detalhes,
            file_name='detalhes_protocolado.csv',
            mime='text/csv',
            key='download_protocolado_csv'
        )
    else:
        st.info("N√£o h√° dados de PROTOCOLADO na planilha para exibir detalhes.") 

    st.markdown("---")

    # --- Se√ß√£o CARR√ÉO ---
    df_carrao_final = df_final[df_final['MESA'] == 'CARR√ÉO'].copy()
    if not df_carrao_final.empty:
        # Verificar se a coluna Pasta C/Emiss√£o Conclu√≠da existe
        if 'Pasta C/Emiss√£o Conclu√≠da' not in df_carrao_final.columns:
            print("ALERTA: Criando coluna 'Pasta C/Emiss√£o Conclu√≠da' em df_carrao_final")
            df_carrao_final['Pasta C/Emiss√£o Conclu√≠da'] = 0
            
        # Garantir que √© um n√∫mero inteiro para exibi√ß√£o
        df_carrao_final['Pasta C/Emiss√£o Conclu√≠da'] = pd.to_numeric(df_carrao_final['Pasta C/Emiss√£o Conclu√≠da'], errors='coerce').fillna(0).astype(int)
        # Calcular total de Pasta C/Emiss√£o Conclu√≠da para CARR√ÉO
        total_carrao = df_carrao_final['Pasta C/Emiss√£o Conclu√≠da'].sum()

        # Exibir card de CARR√ÉO com design mais profissional e harm√¥nico
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        ">
            <div style="
                color: #495057;
                font-size: 14px;
                font-weight: 600;
                text-transform: uppercase;
                letter-spacing: 0.5px;
                margin-bottom: 8px;
                text-align: center;
            ">TOTAL DE PASTAS COM EMISS√ÉO CONCLU√çDA (CARR√ÉO)</div>
            <div style="
                color: #212529;
                font-size: 28px;
                font-weight: 700;
                text-align: center;
                margin: 0;
            ">{int(total_carrao)} PASTAS</div>
        </div>
        """, unsafe_allow_html=True)
        st.markdown("---")

        if 'PASTAS TOTAIS' in df_carrao_final.columns:
            df_carrao_final.loc[:, 'PASTAS TOTAIS'] = pd.to_numeric(df_carrao_final['PASTAS TOTAIS'], errors='coerce').fillna(0).astype(int)

        df_total_carrao = df_carrao_final.select_dtypes(include=np.number).sum().to_frame().T
        df_total_carrao['MESA'] = 'TOTAL'
        df_display_carrao = pd.concat([df_carrao_final, df_total_carrao], ignore_index=True)

        # Aplicar formata√ß√£o num√©rica para garantir compatibilidade com Arrow
        df_display_carrao = ensure_numeric_display(df_display_carrao)
        
        # Formatar as colunas de porcentagem antes de converter para HTML
        df_percent_carrao = df_display_carrao.copy()
        if 'CONVERS√ÉO (%)' in df_percent_carrao.columns:
            df_percent_carrao['CONVERS√ÉO (%)'] = df_percent_carrao['CONVERS√ÉO (%)'].apply(lambda x: f"{x:.2f}%")
        if 'Taxa Emiss√£o Conclu√≠da (%)' in df_percent_carrao.columns:
            df_percent_carrao['Taxa Emiss√£o Conclu√≠da (%)'] = df_percent_carrao['Taxa Emiss√£o Conclu√≠da (%)'].apply(lambda x: f"{x:.2f}%")
        
        # Converter para HTML e exibir
        html_table_carrao = df_percent_carrao.to_html(index=False, classes='dataframe')
        st.markdown(html_table_carrao, unsafe_allow_html=True)
        
        csv_carrao_detalhes = convert_df_to_csv(df_carrao_final)
        st.download_button(
            label="Download Detalhes CARR√ÉO como CSV",
            data=csv_carrao_detalhes,
            file_name='detalhes_carrao.csv',
            mime='text/csv',
            key='download_carrao_csv'
        )
    else:
        st.info("N√£o h√° dados de CARR√ÉO na planilha para exibir detalhes.") 

    st.markdown("---")

def calcular_conclusao_corrigida_por_pipeline(row):
    """
    Calcula se uma certid√£o est√° conclu√≠da usando a l√≥gica corrigida para pipeline 104.
    
    CORRIGIDO DEZEMBRO 2024: Mesma l√≥gica aplicada no acompanhamento.py
    
    Pipeline 102 (Par√≥quia): L√≥gica normal
    Pipeline 104 (Pesquisa BR): APENAS SUCCESS ou FAIL s√£o considerados finalizados
    Outros pipelines: L√≥gica normal baseada em mapeamento
    """
    category_id = str(row.get('CATEGORY_ID', ''))
    stage_id = str(row.get('STAGE_ID', ''))
    categoria_emissao = row.get('CATEGORIA_EMISSAO', '')
    
    # Pipeline 102 (Par√≥quia): Tratar como pipeline normal
    if category_id == '102':
        return categoria_emissao == 'Brasileiras Emitida'
    
    # Pipeline 104 (Pesquisa BR): CORRIGIDO - L√≥gica mais restritiva
    elif category_id == '104':
        # CORRE√á√ÉO CR√çTICA: Apenas considerar realmente finalizado
        if 'SUCCESS' in stage_id:
            # Se chegou ao SUCCESS final (se existir mapeamento espec√≠fico)
            return True
        elif 'FAIL' in stage_id:
            # Se foi dispensada/cancelada (processo finalizado)
            return True
        else:
            # Qualquer outro estado (incluindo "PRONTA PARA EMISS√ÉO") N√ÉO √© conclus√£o final
            return False
    
    # Pipelines 92 e 94 (Cart√≥rios): L√≥gica normal baseada no mapeamento
    else:
        return categoria_emissao == 'Brasileiras Emitida' 